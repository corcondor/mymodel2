# mymodel2

## 概要 / Overview

**mymodel2** は、mymodel1（MNIST文字認識）の設計思想を継承しつつ、カラー自然画像（CIFAR-10）に対応した**構造駆動型分類器**である。

本実装は、深層学習・バックプロパゲーション・GPUに依存せず、**CPU上で動作する説明可能な画像認識システム**を目指す実験的研究である。画像を連続値テンソルとして扱うのではなく、**二値マスク・論理構造・幾何的パターン**として捉え、手作業で設計した特徴量と軽量な分類器を組み合わせる。

### 主要な特徴

- **D4二面体群の対称性**: 回転・反転に対する不変性をグループ理論で実装
- **局所二値パターン (LBP)**: テクスチャ解析による局所構造の捕捉
- **形態学的セルオートマトン**: 二値マスクの動的進化による多様な構造表現
- **Opponent色空間**: 人間の色知覚に近いR-G、Y-B軸による色特徴抽出
- **ストリーミング分散計算**: メモリ効率的なFisher風対角スケーリング
- **複数分類器対応**: パーセプトロン・対角LDA・LightGBMから選択可能

GPU不要・整数演算中心の設計により、**説明可能で再現性の高いCPU実装**を実現している。

---

## 本実装が使用しないもの / What this is NOT

本実装は以下を**使用しない**：

* 畳み込みニューラルネットワーク（CNN）
* Vision Transformer（ViT）
* バックプロパゲーション
* GPU / CUDA
* 自動微分フレームワーク（PyTorchのnn.Module等）
* 大規模BLAS行列演算

「学習にすべてを丸投げする」アプローチではなく、**表現は人間が設計し、判断のみを軽量に学習する**という立場を取る。

---

## 数学的・理論的背景 / Mathematical Background

### 1. D4二面体群による対称性

**二面体群 D₄** は、正方形の対称性を表す8元群である：

```
D₄ = {e, r, r², r³, s, sr, sr², sr³}
```

ここで：
- `r` : 90度反時計回りの回転
- `s` : 水平方向の鏡映（flip）
- `e` : 恒等変換

本実装では、入力画像に対してD₄群の全8要素を作用させ、**軌道（orbit）全体を集約**することで回転・反転不変特徴を構成する：

```python
def extract_d4_invariant(img, pooling='mean'):
    orbit = [transform(img, g) for g in D4]
    features = [extract(x) for x in orbit]
    return aggregate(features, method=pooling)  # mean/max/median
```

これは**群不変量（group invariant）**の構成として、幾何学的深層学習（Geometric Deep Learning）における対称性の取り扱いと数学的に等価である。

#### 理論的根拠

画像認識において、物体の向きや鏡映は本質的意味を持たないことが多い。D₄不変性を導入することで：

1. **データ拡張の明示的実現**: 学習データの8倍拡張を特徴量レベルで実現
2. **射影不変性**: 群作用下で不変な表現により、より本質的な特徴を捕捉
3. **幾何的正則化**: 対称性の事前知識を組み込むことで、過学習を抑制

---

### 2. 局所二値パターン（Local Binary Pattern, LBP）

LBPは、テクスチャ解析の古典的手法であり、各ピクセルの周囲8近傍との強度比較により、**局所的な空間構造**を捉える。

#### 定義

中心ピクセル `c` の周囲8近傍を `{p₀, p₁, ..., p₇}` とすると、LBPコードは：

```
LBP(c) = Σᵢ s(pᵢ - c) × 2ⁱ
```

ここで `s(x) = 1 (x ≥ 0)`, `s(x) = 0 (x < 0)`

#### 理論的意義

- **照明不変性**: 絶対輝度ではなく、相対的な明暗パターンを捉えるため、照明変動に頑健
- **テクスチャの記述子**: 256次元のヒストグラムとして、画像のテクスチャを特徴付け
- **flip不変性の拡張**: 本実装では、鏡映対称なコードを同一視することで、さらに頑健性を向上

```python
lbp_hist8(gray, eps=0, flip_invariant=True)
```

---

### 3. 形態学的セルオートマトン（Morphological Cellular Automaton）

セルオートマトン（CA）は、格子点上の局所的規則により、系全体の動的進化を記述する数理モデルである。本実装では、**二値マスクに対するCA**を導入し、マスクの時間発展を特徴量として活用する。

#### 更新規則

各セル `B[i,j]` の次状態は、近傍セル数 `N` に依存：

```
B'[i,j] = 1  if  (B[i,j] = 0 かつ birth_min ≤ N ≤ birth_max)  [誕生]
             or  (B[i,j] = 1 かつ survive_min ≤ N ≤ survive_max)  [生存]
         = 0  otherwise  [死滅]
```

#### 理論的意義

1. **動的構造の捕捉**: 静的なマスクだけでなく、その形態学的進化により、複雑な構造を表現
2. **多様な特徴生成**: CA各ステップのマスクを独立に特徴化することで、特徴空間を豊かに
3. **膨張・収縮の一般化**: 従来の形態学的演算（dilation/erosion）をCAとして統一的に記述

```python
run_morph_ca(mask, steps=3, birth_min=5, birth_max=8, 
             survive_min=4, survive_max=8, use_diag=True)
```

---

### 4. Opponent色空間と色彩特徴

人間の視覚系は、**opponent色理論**に基づき、色を以下の軸で知覚する：

- **R-G軸**: 赤と緑の対立
- **Y-B軸**: 黄と青の対立
- **明度軸**: 白と黒の対立

本実装では、RGB画像から以下を計算：

```
rg = R - G
yb = 2B - R - G
saturation = max(R,G,B) - min(R,G,B)
```

#### 理論的根拠

1. **知覚的意味**: RGBは物理的だが、opponent色空間は人間の知覚に近い
2. **色の分離**: 色相情報をR-G、Y-B軸で捉え、彩度で色の強さを分離
3. **閾値処理の自然性**: 各軸で閾値処理を行うことで、色の方向性を二値マスクとして抽出

これにより、CIFAR-10のような自然画像における色情報を効果的に活用する。

---

### 5. Fisher風対角スケーリング

分類問題において、特徴量の分散を正規化することは、**Fisherの線形判別分析（LDA）**の考え方に通じる。本実装では、メモリ効率を重視し、**対角共分散のみを考慮**した簡易版を採用。

#### アルゴリズム

1. **ストリーミング統計計算（Welfordアルゴリズム）**: 大規模データに対し、平均と分散をオンライン更新

```
n, mean, M2 を更新
var = M2 / n
```

2. **対角スケーリング**:

```
x' = x / sqrt(var + ε) × scale
```

ここで `ε` は数値安定性のための微小正則化、`scale` は量子化のためのスケール係数。

#### 理論的意義

- **特徴の正規化**: 各特徴の分散を揃えることで、分類器の学習を安定化
- **Fisher判別との関連**: 完全なLDAは共分散行列の逆行列が必要だが、対角近似により計算コストを大幅削減
- **整数演算との両立**: スケーリング後に量子化することで、整数ベース分類器（パーセプトロン）との親和性を維持

```python
invstd = fit_diag_invstd_stream(features, use_var=True, eps=1e-6)
scaled_features = features * invstd * 16.0  # 整数化
```

---

### 6. 分類器の選択肢

本実装は3種類の分類器をサポート：

#### (a) 平均化マージンパーセプトロン

**パーセプトロン**は、最も単純な線形分類器である。本実装では以下の拡張を施す：

- **マージン**: 正解クラスと次点クラスのスコア差が閾値を超えるまで更新
- **クリッピング**: 重みの絶対値を制限し、過学習を抑制
- **平均化**: 学習過程の重みを累積平均することで、安定性を向上

更新式：

```
if y_pred ≠ y_true or score[y_true] < score[y_runner] + margin:
    W[y_true] += step × x
    W[y_pred] -= step × x
    W = clip(W, -wmax, wmax)
```

#### (b) 対角LDA

対角近似した線形判別分析。クラスごとの平均と、プールされた対角共分散を用いる。

決定関数：

```
score_c(x) = xᵀ Σ⁻¹ μ_c - 0.5 μ_cᵀ Σ⁻¹ μ_c + log(P(c))
```

ここで `Σ` は対角行列。

#### (c) LightGBM

勾配ブースティング決定木（GBDT）のライブラリ。非線形分類が可能で、特徴の相互作用を自動学習。

- 特徴量の相互作用を木構造で表現
- CPU並列化により高速学習
- 整数特徴との親和性が高い

---

## mymodel1からの主要な変更点 / Changes from mymodel1

mymodel1は**MNIST（28×28グレースケール手書き数字）**を対象としていたが、mymodel2は**CIFAR-10（32×32カラー自然画像）**に対応している。この移行に伴い、以下の大幅な拡張・変更を実施した。

### 1. 入力の変更: グレースケール → カラー

| 項目 | mymodel1 (MNIST) | mymodel2 (CIFAR-10) |
|------|------------------|---------------------|
| 画像サイズ | 28×28 | 32×32 |
| チャンネル | 1（グレースケール） | 3（RGB） |
| 画像内容 | 手書き数字（単純構造） | 自然物体（複雑テクスチャ） |

**対応策**:
- グレースケール特徴は引き続き使用（RGB→グレー変換）
- **Opponent色空間特徴を新規追加**: R-G、Y-B、彩度マスク
- **RGBブロック平均**: 4×4ブロックごとのRGB平均値
- **粗いRGBヒストグラム**: 4³=64ビンのカラーヒストグラム

### 2. 対称性の拡張: D4二面体群の導入

mymodel1では、回転・反転に対する明示的な不変性はなかった。mymodel2では：

- **D4群の全8変換を生成**: `d4_group_transforms(img)` により、回転と鏡映の全組み合わせ
- **軌道集約による不変特徴**: `extract_d4_invariant()` で平均/最大値/中央値による集約
- **オプション**: `--use_d4` フラグで有効化（特徴抽出が8倍遅くなるトレードオフ）

### 3. テクスチャ解析: LBPの追加

CIFAR-10の自然画像は、MNISTの手書き文字に比べて**テクスチャ情報が豊富**である。

- **LBP 8近傍ヒストグラム**: 256次元のテクスチャ記述子
- **flip不変オプション**: `lbp_flip_invariant=True` で、鏡映対称なパターンを統合
- **閾値パラメータ**: `lbp_eps` で比較の厳しさを調整

### 4. 動的特徴: 形態学的セルオートマトン

mymodel1では二値マスクは静的であったが、mymodel2では：

- **CAによる時間発展**: 各マスクを `ca_steps` ステップ進化させ、各ステップを独立に特徴化
- **パラメータ調整可能**: 誕生・生存条件、近傍の種類（4近傍/8近傍）を指定可能
- **特徴量の増幅**: CAステップ数に応じて特徴次元が倍増（`n_masks × (1 + ca_steps)`）

### 5. メモリ管理: メモリマップとストリーミング計算

CIFAR-10は50,000枚の訓練画像を持ち、特徴次元も数千〜数万に達する。メモリ不足を回避するため：

- **memmapによる特徴キャッシュ**: `build_features_memmap()` で特徴をディスク上に保存
- **ストリーミング統計**: `RunningStats` クラスにより、メモリに乗り切らないデータの平均・分散を計算
- **チャンク処理**: 特徴抽出・スケーリングを小バッチで逐次処理

### 6. 分類器の多様化

mymodel1はパーセプトロン単体だったが、mymodel2では：

- **対角LDA**: ガウス仮定下の確率的分類器
- **LightGBM**: 非線形ブースティング木（オプション、要インストール）
- **flip augmentation**: 訓練時・評価時の左右反転アンサンブル

### 7. 実装の工業化

- **並列特徴抽出**: `ThreadPoolExecutor` による複数コア活用
- **設定のハッシュ管理**: 特徴設定の変更を自動検知し、キャッシュ無効化
- **モデルの保存/読み込み**: LightGBMモデルをpickle形式で永続化

### 8. 特徴次元の比較

| 項目 | mymodel1 (推定) | mymodel2 (デフォルト) |
|------|----------------|----------------------|
| 二値マスク数 | 〜10 | 〜30 |
| マスクあたり特徴 | 〜80 | 〜90 (cnt+row+col+grid+pat+markov) |
| LBP | なし | 256 |
| カラー特徴 | なし | 48 (block) + 64 (hist) |
| CA拡張 | なし | ×(1 + ca_steps) |
| **合計次元** | 〜1,000 | **3,000〜10,000** |

---

## 実装の詳細 / Implementation Details

### 特徴抽出パイプライン

```
入力画像 (32×32×3, RGB)
    ↓
┌─────────────────────────────────────────┐
│ 1. グレースケール変換                    │
│    gray = 0.3R + 0.59G + 0.11B          │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│ 2. 二値マスク生成                        │
│   - グレー閾値マスク (6種)               │
│   - エッジマスク (6種)                   │
│   - 勾配方向マスク (4方向)               │
│   - R-G正負マスク (6種)                  │
│   - Y-B正負マスク (6種)                  │
│   - 彩度マスク (3種)                     │
│   合計: 31マスク                         │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│ 3. セルオートマトン展開 (オプション)      │
│   各マスク → CA進化 → 複数時刻のマスク   │
│   マスク数 × (1 + ca_steps)             │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│ 4. マスクごとの特徴統計                  │
│   - カウント (1)                         │
│   - 行/列投影 (8+8)                      │
│   - 8×8グリッド (64)                     │
│   - 2×2パターンヒストグラム (16)         │
│   - マルコフ遷移 (16, オプション)        │
│   = 93次元/マスク                        │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│ 5. グローバル特徴                        │
│   - LBPヒストグラム (256)                │
│   - RGBブロック平均 (48)                 │
│   - RGB粗ヒストグラム (64)               │
│   - バイアス項 (1)                       │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│ 6. 連結・量子化                          │
│   全特徴を結合 → int16配列               │
│   (メモリ効率: float32の半分)           │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│ 7. 対角スケーリング (オプション)         │
│   x' = x / sqrt(var + ε) × 16           │
└─────────────────────────────────────────┘
    ↓
    分類器へ (Perceptron / DiagLDA / LightGBM)
```

---

## 使用方法 / Usage

### 必要環境

- Python 3.8以上
- NumPy
- LightGBM（オプション、`--classifier lightgbm` 使用時のみ）

```bash
pip install numpy
pip install lightgbm  # オプション
```

### 基本実行

```bash
# デフォルト設定（パーセプトロン）
python mymodel2.py

# 対角LDAを使用
python mymodel2.py --classifier diaglda

# LightGBMを使用（要インストール）
python mymodel2.py --classifier lightgbm
```

### 主要オプション

#### データ・キャッシュ

```bash
--data_root ./cifar10_data        # CIFAR-10ダウンロード先
--cache_dir ./feat_cache           # 特徴キャッシュディレクトリ
--force_feat                       # 特徴キャッシュを無視して再計算
```

#### 特徴設定

```bash
--gray_thresholds 40,60,80,100,120,140  # グレー閾値リスト
--grad_th 12                            # 勾配閾値
--rg_tpos 20,50,80                      # R-G軸閾値
--yb_tpos 20,50,80                      # Y-B軸閾値
--sat_th 30,60,90                       # 彩度閾値
--blocks 4                              # RGBブロック分割数
--color_hist_bins 4                     # RGBヒストグラムのビン数
--lbp_eps 0                             # LBP比較閾値
--lbp_flip_invariant                    # LBPの鏡映不変化
```

#### セルオートマトン

```bash
--ca_steps 3                    # CA進化ステップ数（0=無効）
--ca_birth_min 5                # 誕生条件の最小近傍数
--ca_birth_max 8                # 誕生条件の最大近傍数
--ca_survive_min 4              # 生存条件の最小近傍数
--ca_survive_max 8              # 生存条件の最大近傍数
--ca_no_diag                    # 対角近傍を無効化
```

#### D4対称性

```bash
--use_d4                        # D4不変特徴を使用（8倍遅い）
--d4_pooling mean               # mean/max/median
```

#### 対角スケーリング

```bash
--diag_scale                    # 対角スケーリングを有効化
--diag_use_var                  # 分散ベース（デフォルト）
--no_diag_use_var               # 二乗平均ベース
--diag_eps 1e-6                 # 正則化パラメータ
--diag_scale_factor 16.0        # スケール係数
```

#### パーセプトロン設定

```bash
--epochs 8                      # エポック数
--step 1                        # 更新ステップサイズ
--wmax 12000                    # 重みクリッピング閾値
--margin 80                     # マージン
```

#### LightGBM設定

```bash
--classifier lightgbm
--lgbm_n_estimators 500         # ブースティング回数
--lgbm_max_depth 8              # 木の深さ
--lgbm_num_leaves 256           # 葉の数
--lgbm_learning_rate 0.05       # 学習率
--save_model model.pkl          # 学習済みモデル保存
--load_model model.pkl          # 学習済みモデル読み込み
```

#### データ拡張

```bash
--flip_train                    # 訓練時に左右反転を使用
--flip_eval                     # 評価時に左右反転アンサンブル
```

#### パフォーマンス

```bash
--chunk_feat 512                # 特徴抽出のバッチサイズ
--num_workers 1                 # 並列ワーカー数（0=シーケンシャル）
--seed 0                        # 乱数シード
```

### 実行例

#### 例1: 高精度設定（D4不変性 + LightGBM）

```bash
python mymodel2.py \
  --use_d4 \
  --d4_pooling mean \
  --classifier lightgbm \
  --lgbm_n_estimators 1000 \
  --flip_eval \
  --diag_scale \
  --num_workers 4
```

#### 例2: 高速設定（CA無効 + パーセプトロン）

```bash
python mymodel2.py \
  --ca_steps 0 \
  --no_lbp \
  --classifier perceptron \
  --epochs 5
```

#### 例3: セルオートマトン探索

```bash
python mymodel2.py \
  --ca_steps 5 \
  --ca_birth_min 4 \
  --ca_birth_max 7 \
  --ca_survive_min 3 \
  --ca_survive_max 6
```

---

## パフォーマンスと制約 / Performance & Limitations

### 期待される精度

- **パーセプトロン（デフォルト）**: 50〜60%
- **対角LDA**: 55〜65%
- **LightGBM（D4+対角スケーリング）**: 70〜75%

（CIFAR-10の最新SOTA: 99%以上。本手法は説明可能性重視であり、精度は副次的目標）

### 計算時間（Intel Core i7, 1コア）

- 特徴抽出（50,000枚、CA無効）: 〜5分
- 特徴抽出（D4有効）: 〜40分（8倍）
- パーセプトロン学習（8エポック）: 〜1分
- LightGBM学習（500木）: 〜10分

### メモリ使用量

- 特徴キャッシュ（50,000×5,000次元、int16）: 〜500MB
- ピークメモリ: 〜2GB

---

## 設計思想 / Design Philosophy

### なぜGPUを使わないのか？

1. **再現性**: 誰でも、どこでも、同じ結果を得られる
2. **説明可能性**: 各特徴の意味が明確で、デバッグが容易
3. **組み込み適性**: エッジデバイスや省電力環境での動作を想定
4. **原理の検証**: 「学習に任せる」のではなく、「構造を設計する」アプローチの探究

### mymodel2の目的

本実装は、**深層学習の代替**や**SOTAの更新**を目指すものではない。

その目的は：

- 画像認識における**構造的・幾何的プリミティブ**の探究
- **説明可能で制御可能**な特徴表現の実現
- 深層学習とは異なる**設計主導型アプローチ**の可能性検証

**「学習にすべてを任せる」のではなく、「理解可能な部品を組み合わせる」**という、もう一つの画像認識の形を提示する。

---

## ライセンス / License

MIT License (LICENSE ファイルを参照)

---

## 参考文献 / References

- **D4群と幾何学的深層学習**: Cohen & Welling, "Group Equivariant Convolutional Networks", ICML 2016
- **局所二値パターン**: Ojala et al., "Multiresolution Gray-Scale and Rotation Invariant Texture Classification with Local Binary Patterns", TPAMI 2002
- **形態学的演算**: Serra, "Image Analysis and Mathematical Morphology", Academic Press 1982
- **Opponent色理論**: Hering, "Outlines of a Theory of the Light Sense", 1878
- **Welfordアルゴリズム**: Welford, "Note on a Method for Calculating Corrected Sums of Squares and Products", Technometrics 1962
- **Fisher線形判別**: Fisher, "The Use of Multiple Measurements in Taxonomic Problems", Annals of Eugenics 1936

---

## 今後の展開 / Future Work

- **グラフ畳み込み**: マスク間の関係をグラフ構造として表現
- **Cayleyグラフ上の畳み込み**: D4群の構造を明示的に利用
- **動的マスク生成**: 強化学習によるマスク閾値の自動最適化
- **他データセットへの適用**: ImageNet-1k、STL-10等
- **組み込み実装**: マイコン・FPGA向けの整数専用版

---

## 謝辞 / Acknowledgments

本実装は、mymodel1の設計思想を継承しつつ、カラー画像認識への拡張を試みたものである。構造駆動型アプローチの可能性を信じ、実験的研究を続ける全ての研究者に敬意を表する。
