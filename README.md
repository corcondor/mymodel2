# mymodel2

## 概要 / Overview

**mymodel2** は、mymodel1（MNIST文字認識）の設計思想を継承しつつ、カラー自然画像（CIFAR-10）に対応した**構造駆動型分類器**である。

本実装は、深層学習・バックプロパゲーション・GPUに依存せず、**CPU上で動作する説明可能な画像認識システム**を目指す実験的研究である。画像を連続値テンソルとして扱うのではなく、**二値マスク・論理構造・幾何的パターン**として捉え、手作業で設計した特徴量と軽量な分類器を組み合わせる。

### 主要な特徴

- **D4二面体群の対称性**: 回転・反転に対する不変性をグループ理論で実装
- **局所二値パターン (LBP)**: テクスチャ解析による局所構造の捕捉
- **形態学的セルオートマトン**: 二値マスクの動的進化による多様な構造表現
- **Opponent色空間**: 人間の色知覚に近いR-G、Y-B軸による色特徴抽出
- **ストリーミング分散計算**: メモリ効率的なFisher風対角スケーリング
- **複数分類器対応**: パーセプトロン・対角LDA・LightGBMから選択可能

GPU不要・整数演算中心の設計により、**説明可能で再現性の高いCPU実装**を実現している。

---

## 本実装が使用しないもの / What this is NOT

本実装は以下を**使用しない**：

* 畳み込みニューラルネットワーク（CNN）
* Vision Transformer（ViT）
* バックプロパゲーション
* GPU / CUDA
* 自動微分フレームワーク（PyTorchのnn.Module等）
* 大規模BLAS行列演算

「学習にすべてを丸投げする」アプローチではなく、**表現は人間が設計し、判断のみを軽量に学習する**という立場を取る。

---

## 数学的・理論的背景 / Mathematical Background

### 1. D4二面体群による対称性

**二面体群 D₄** は、正方形の対称性を表す8元群である：

```
D₄ = {e, r, r², r³, s, sr, sr², sr³}
```

ここで：
- `r` : 90度反時計回りの回転
- `s` : 水平方向の鏡映（flip）
- `e` : 恒等変換

本実装では、入力画像に対してD₄群の全8要素を作用させ、**軌道（orbit）全体を集約**することで回転・反転不変特徴を構成する：

```python
def extract_d4_invariant(img, pooling='mean'):
    orbit = [transform(img, g) for g in D4]
    features = [extract(x) for x in orbit]
    return aggregate(features, method=pooling)  # mean/max/median
```

これは**群不変量（group invariant）**の構成として、幾何学的深層学習（Geometric Deep Learning）における対称性の取り扱いと数学的に等価である。

#### 理論的根拠

画像認識において、物体の向きや鏡映は本質的意味を持たないことが多い。D₄不変性を導入することで：

1. **データ拡張の明示的実現**: 学習データの8倍拡張を特徴量レベルで実現
2. **射影不変性**: 群作用下で不変な表現により、より本質的な特徴を捕捉
3. **幾何的正則化**: 対称性の事前知識を組み込むことで、過学習を抑制

---

### 2. 局所二値パターン（Local Binary Pattern, LBP）

LBPは、テクスチャ解析の古典的手法であり、各ピクセルの周囲8近傍との強度比較により、**局所的な空間構造**を捉える。

#### 定義

中心ピクセル `c` の周囲8近傍を `{p₀, p₁, ..., p₇}` とすると、LBPコードは：

```
LBP(c) = Σᵢ s(pᵢ - c) × 2ⁱ
```

ここで `s(x) = 1 (x ≥ 0)`, `s(x) = 0 (x < 0)`

#### 理論的意義

- **照明不変性**: 絶対輝度ではなく、相対的な明暗パターンを捉えるため、照明変動に頑健
- **テクスチャの記述子**: 256次元のヒストグラムとして、画像のテクスチャを特徴付け
- **flip不変性の拡張**: 本実装では、鏡映対称なコードを同一視することで、さらに頑健性を向上

```python
lbp_hist8(gray, eps=0, flip_invariant=True)
```

---

### 3. 形態学的セルオートマトン（Morphological Cellular Automaton）

セルオートマトン（CA）は、格子点上の局所的規則により、系全体の動的進化を記述する数理モデルである。本実装では、**二値マスクに対するCA**を導入し、マスクの時間発展を特徴量として活用する。

#### 更新規則

各セル `B[i,j]` の次状態は、近傍セル数 `N` に依存：

```
B'[i,j] = 1  if  (B[i,j] = 0 かつ birth_min ≤ N ≤ birth_max)  [誕生]
             or  (B[i,j] = 1 かつ survive_min ≤ N ≤ survive_max)  [生存]
         = 0  otherwise  [死滅]
```

#### 理論的意義

1. **動的構造の捕捉**: 静的なマスクだけでなく、その形態学的進化により、複雑な構造を表現
2. **多様な特徴生成**: CA各ステップのマスクを独立に特徴化することで、特徴空間を豊かに
3. **膨張・収縮の一般化**: 従来の形態学的演算（dilation/erosion）をCAとして統一的に記述

```python
run_morph_ca(mask, steps=3, birth_min=5, birth_max=8, 
             survive_min=4, survive_max=8, use_diag=True)
```

---

### 4. Opponent色空間と色彩特徴

人間の視覚系は、**opponent色理論**に基づき、色を以下の軸で知覚する：

- **R-G軸**: 赤と緑の対立
- **Y-B軸**: 黄と青の対立
- **明度軸**: 白と黒の対立

本実装では、RGB画像から以下を計算：

```
rg = R - G
yb = 2B - R - G
saturation = max(R,G,B) - min(R,G,B)
```

#### 理論的根拠

1. **知覚的意味**: RGBは物理的だが、opponent色空間は人間の知覚に近い
2. **色の分離**: 色相情報をR-G、Y-B軸で捉え、彩度で色の強さを分離
3. **閾値処理の自然性**: 各軸で閾値処理を行うことで、色の方向性を二値マスクとして抽出

これにより、CIFAR-10のような自然画像における色情報を効果的に活用する。

---

### 5. Fisher風対角スケーリング

分類問題において、特徴量の分散を正規化することは、**Fisherの線形判別分析（LDA）**の考え方に通じる。本実装では、メモリ効率を重視し、**対角共分散のみを考慮**した簡易版を採用。

#### アルゴリズム

1. **ストリーミング統計計算（Welfordアルゴリズム）**: 大規模データに対し、平均と分散をオンライン更新

```
n, mean, M2 を更新
var = M2 / n
```

2. **対角スケーリング**:

```
x' = x / sqrt(var + ε) × scale
```

ここで `ε` は数値安定性のための微小正則化、`scale` は量子化のためのスケール係数。

#### 理論的意義

- **特徴の正規化**: 各特徴の分散を揃えることで、分類器の学習を安定化
- **Fisher判別との関連**: 完全なLDAは共分散行列の逆行列が必要だが、対角近似により計算コストを大幅削減
- **整数演算との両立**: スケーリング後に量子化することで、整数ベース分類器（パーセプトロン）との親和性を維持

```python
invstd = fit_diag_invstd_stream(features, use_var=True, eps=1e-6)
scaled_features = features * invstd * 16.0  # 整数化
```

---

### 6. 分類器の選択肢

本実装は3種類の分類器をサポート：

#### (a) 平均化マージンパーセプトロン

**パーセプトロン**は、最も単純な線形分類器である。本実装では以下の拡張を施す：

- **マージン**: 正解クラスと次点クラスのスコア差が閾値を超えるまで更新
- **クリッピング**: 重みの絶対値を制限し、過学習を抑制
- **平均化**: 学習過程の重みを累積平均することで、安定性を向上

更新式：

```
if y_pred ≠ y_true or score[y_true] < score[y_runner] + margin:
    W[y_true] += step × x
    W[y_pred] -= step × x
    W = clip(W, -wmax, wmax)
```

#### (b) 対角LDA

対角近似した線形判別分析。クラスごとの平均と、プールされた対角共分散を用いる。

決定関数：

```
score_c(x) = xᵀ Σ⁻¹ μ_c - 0.5 μ_cᵀ Σ⁻¹ μ_c + log(P(c))
```

ここで `Σ` は対角行列。

#### (c) LightGBM

勾配ブースティング決定木（GBDT）のライブラリ。非線形分類が可能で、特徴の相互作用を自動学習。

- 特徴量の相互作用を木構造で表現
- CPU並列化により高速学習
- 整数特徴との親和性が高い

---

## mymodel1からの主要な変更点 / Changes from mymodel1

mymodel1は**MNIST（28×28グレースケール手書き数字）**を対象としていたが、mymodel2は**CIFAR-10（32×32カラー自然画像）**に対応している。この移行に伴い、以下の大幅な拡張・変更を実施した。

### 1. 入力の変更: グレースケール → カラー

| 項目 | mymodel1 (MNIST) | mymodel2 (CIFAR-10) |
|------|------------------|---------------------|
| 画像サイズ | 28×28 | 32×32 |
| チャンネル | 1（グレースケール） | 3（RGB） |
| 画像内容 | 手書き数字（単純構造） | 自然物体（複雑テクスチャ） |

**対応策**:
- グレースケール特徴は引き続き使用（RGB→グレー変換）
- **Opponent色空間特徴を新規追加**: R-G、Y-B、彩度マスク
- **RGBブロック平均**: 4×4ブロックごとのRGB平均値
- **粗いRGBヒストグラム**: 4³=64ビンのカラーヒストグラム

### 2. 対称性の拡張: D4二面体群の導入

mymodel1では、回転・反転に対する明示的な不変性はなかった。mymodel2では：

- **D4群の全8変換を生成**: `d4_group_transforms(img)` により、回転と鏡映の全組み合わせ
- **軌道集約による不変特徴**: `extract_d4_invariant()` で平均/最大値/中央値による集約
- **オプション**: `--use_d4` フラグで有効化（特徴抽出が8倍遅くなるトレードオフ）

### 3. テクスチャ解析: LBPの追加

CIFAR-10の自然画像は、MNISTの手書き文字に比べて**テクスチャ情報が豊富**である。

- **LBP 8近傍ヒストグラム**: 256次元のテクスチャ記述子
- **flip不変オプション**: `lbp_flip_invariant=True` で、鏡映対称なパターンを統合
- **閾値パラメータ**: `lbp_eps` で比較の厳しさを調整

### 4. 動的特徴: 形態学的セルオートマトン

mymodel1では二値マスクは静的であったが、mymodel2では：

- **CAによる時間発展**: 各マスクを `ca_steps` ステップ進化させ、各ステップを独立に特徴化
- **パラメータ調整可能**: 誕生・生存条件、近傍の種類（4近傍/8近傍）を指定可能
- **特徴量の増幅**: CAステップ数に応じて特徴次元が倍増（`n_masks × (1 + ca_steps)`）

### 5. メモリ管理: メモリマップとストリーミング計算

CIFAR-10は50,000枚の訓練画像を持ち、特徴次元も数千〜数万に達する。メモリ不足を回避するため：

- **memmapによる特徴キャッシュ**: `build_features_memmap()` で特徴をディスク上に保存
- **ストリーミング統計**: `RunningStats` クラスにより、メモリに乗り切らないデータの平均・分散を計算
- **チャンク処理**: 特徴抽出・スケーリングを小バッチで逐次処理

### 6. 分類器の多様化

mymodel1はパーセプトロン単体だったが、mymodel2では：

- **対角LDA**: ガウス仮定下の確率的分類器
- **LightGBM**: 非線形ブースティング木（オプション、要インストール）
- **flip augmentation**: 訓練時・評価時の左右反転アンサンブル

### 7. 実装の工業化

- **並列特徴抽出**: `ThreadPoolExecutor` による複数コア活用
- **設定のハッシュ管理**: 特徴設定の変更を自動検知し、キャッシュ無効化
- **モデルの保存/読み込み**: LightGBMモデルをpickle形式で永続化

### 8. 特徴次元の比較

| 項目 | mymodel1 (推定) | mymodel2 (デフォルト) |
|------|----------------|----------------------|
| 二値マスク数 | 〜10 | 〜30 |
| マスクあたり特徴 | 〜80 | 〜90 (cnt+row+col+grid+pat+markov) |
| LBP | なし | 256 |
| カラー特徴 | なし | 48 (block) + 64 (hist) |
| CA拡張 | なし | ×(1 + ca_steps) |
| **合計次元** | 〜1,000 | **3,000〜10,000** |

---

## 実装の詳細 / Implementation Details

### 特徴抽出パイプライン

```
入力画像 (32×32×3, RGB)
    ↓
┌─────────────────────────────────────────┐
│ 1. グレースケール変換                    │
│    gray = 0.3R + 0.59G + 0.11B          │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│ 2. 二値マスク生成                        │
│   - グレー閾値マスク (6種)               │
│   - エッジマスク (6種)                   │
│   - 勾配方向マスク (4方向)               │
│   - R-G正負マスク (6種)                  │
│   - Y-B正負マスク (6種)                  │
│   - 彩度マスク (3種)                     │
│   合計: 31マスク                         │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│ 3. セルオートマトン展開 (オプション)      │
│   各マスク → CA進化 → 複数時刻のマスク   │
│   マスク数 × (1 + ca_steps)             │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│ 4. マスクごとの特徴統計                  │
│   - カウント (1)                         │
│   - 行/列投影 (8+8)                      │
│   - 8×8グリッド (64)                     │
│   - 2×2パターンヒストグラム (16)         │
│   - マルコフ遷移 (16, オプション)        │
│   = 93次元/マスク                        │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│ 5. グローバル特徴                        │
│   - LBPヒストグラム (256)                │
│   - RGBブロック平均 (48)                 │
│   - RGB粗ヒストグラム (64)               │
│   - バイアス項 (1)                       │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│ 6. 連結・量子化                          │
│   全特徴を結合 → int16配列               │
│   (メモリ効率: float32の半分)           │
└─────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────┐
│ 7. 対角スケーリング (オプション)         │
│   x' = x / sqrt(var + ε) × 16           │
└─────────────────────────────────────────┘
    ↓
    分類器へ (Perceptron / DiagLDA / LightGBM)
```

---

## 使用方法 / Usage

### 必要環境

- Python 3.8以上
- NumPy
- LightGBM（オプション、`--classifier lightgbm` 使用時のみ）

```bash
pip install numpy
pip install lightgbm  # オプション
```

### 基本実行

```bash
# デフォルト設定（パーセプトロン）
python mymodel2.py

# 対角LDAを使用
python mymodel2.py --classifier diaglda

# LightGBMを使用（要インストール）
python mymodel2.py --classifier lightgbm
```

### 主要オプション

#### データ・キャッシュ

```bash
--data_root ./cifar10_data        # CIFAR-10ダウンロード先
--cache_dir ./feat_cache           # 特徴キャッシュディレクトリ
--force_feat                       # 特徴キャッシュを無視して再計算
```

#### 特徴設定

```bash
--gray_thresholds 40,60,80,100,120,140  # グレー閾値リスト
--grad_th 12                            # 勾配閾値
--rg_tpos 20,50,80                      # R-G軸閾値
--yb_tpos 20,50,80                      # Y-B軸閾値
--sat_th 30,60,90                       # 彩度閾値
--blocks 4                              # RGBブロック分割数
--color_hist_bins 4                     # RGBヒストグラムのビン数
--lbp_eps 0                             # LBP比較閾値
--lbp_flip_invariant                    # LBPの鏡映不変化
```

#### セルオートマトン

```bash
--ca_steps 3                    # CA進化ステップ数（0=無効）
--ca_birth_min 5                # 誕生条件の最小近傍数
--ca_birth_max 8                # 誕生条件の最大近傍数
--ca_survive_min 4              # 生存条件の最小近傍数
--ca_survive_max 8              # 生存条件の最大近傍数
--ca_no_diag                    # 対角近傍を無効化
```

#### D4対称性

```bash
--use_d4                        # D4不変特徴を使用（8倍遅い）
--d4_pooling mean               # mean/max/median
```

#### 対角スケーリング

```bash
--diag_scale                    # 対角スケーリングを有効化
--diag_use_var                  # 分散ベース（デフォルト）
--no_diag_use_var               # 二乗平均ベース
--diag_eps 1e-6                 # 正則化パラメータ
--diag_scale_factor 16.0        # スケール係数
```

#### パーセプトロン設定

```bash
--epochs 8                      # エポック数
--step 1                        # 更新ステップサイズ
--wmax 12000                    # 重みクリッピング閾値
--margin 80                     # マージン
```

#### LightGBM設定

```bash
--classifier lightgbm
--lgbm_n_estimators 500         # ブースティング回数
--lgbm_max_depth 8              # 木の深さ
--lgbm_num_leaves 256           # 葉の数
--lgbm_learning_rate 0.05       # 学習率
--save_model model.pkl          # 学習済みモデル保存
--load_model model.pkl          # 学習済みモデル読み込み
```

#### データ拡張

```bash
--flip_train                    # 訓練時に左右反転を使用
--flip_eval                     # 評価時に左右反転アンサンブル
```

#### パフォーマンス

```bash
--chunk_feat 512                # 特徴抽出のバッチサイズ
--num_workers 1                 # 並列ワーカー数（0=シーケンシャル）
--seed 0                        # 乱数シード
```

### 実行例

#### 例1: 高精度設定（D4不変性 + LightGBM）

```bash
python mymodel2.py \
  --use_d4 \
  --d4_pooling mean \
  --classifier lightgbm \
  --lgbm_n_estimators 1000 \
  --flip_eval \
  --diag_scale \
  --num_workers 4
```

#### 例2: 高速設定（CA無効 + パーセプトロン）

```bash
python mymodel2.py \
  --ca_steps 0 \
  --no_lbp \
  --classifier perceptron \
  --epochs 5
```

#### 例3: セルオートマトン探索

```bash
python mymodel2.py \
  --ca_steps 5 \
  --ca_birth_min 4 \
  --ca_birth_max 7 \
  --ca_survive_min 3 \
  --ca_survive_max 6
```

---

## パフォーマンスと制約 / Performance & Limitations

### 期待される精度

- **パーセプトロン（デフォルト）**: 50〜60%
- **対角LDA**: 55〜65%
- **LightGBM（D4+対角スケーリング）**: 70〜75%

（CIFAR-10の最新SOTA: 99%以上。本手法は説明可能性重視であり、精度は副次的目標）

### 計算時間（Intel Core i7, 1コア）

- 特徴抽出（50,000枚、CA無効）: 〜5分
- 特徴抽出（D4有効）: 〜40分（8倍）
- パーセプトロン学習（8エポック）: 〜1分
- LightGBM学習（500木）: 〜10分

### メモリ使用量

- 特徴キャッシュ（50,000×5,000次元、int16）: 〜500MB
- ピークメモリ: 〜2GB

---

## 設計思想 / Design Philosophy

### なぜGPUを使わないのか？

1. **再現性**: 誰でも、どこでも、同じ結果を得られる
2. **説明可能性**: 各特徴の意味が明確で、デバッグが容易
3. **組み込み適性**: エッジデバイスや省電力環境での動作を想定
4. **原理の検証**: 「学習に任せる」のではなく、「構造を設計する」アプローチの探究

### mymodel2の目的

本実装は、**深層学習の代替**や**SOTAの更新**を目指すものではない。

その目的は：

- 画像認識における**構造的・幾何的プリミティブ**の探究
- **説明可能で制御可能**な特徴表現の実現
- 深層学習とは異なる**設計主導型アプローチ**の可能性検証

**「学習にすべてを任せる」のではなく、「理解可能な部品を組み合わせる」**という、もう一つの画像認識の形を提示する。

---

## ライセンス / License

MIT License (LICENSE ファイルを参照)

---

## 参考文献 / References

- **D4群と幾何学的深層学習**: Cohen & Welling, "Group Equivariant Convolutional Networks", ICML 2016
- **局所二値パターン**: Ojala et al., "Multiresolution Gray-Scale and Rotation Invariant Texture Classification with Local Binary Patterns", TPAMI 2002
- **形態学的演算**: Serra, "Image Analysis and Mathematical Morphology", Academic Press 1982
- **Opponent色理論**: Hering, "Outlines of a Theory of the Light Sense", 1878
- **Welfordアルゴリズム**: Welford, "Note on a Method for Calculating Corrected Sums of Squares and Products", Technometrics 1962
- **Fisher線形判別**: Fisher, "The Use of Multiple Measurements in Taxonomic Problems", Annals of Eugenics 1936

---

## 発展の方向性と設計思想の考察 / Development Paths and Architectural Considerations

### 現在のアプローチの到達点と限界

本実装は、**CPU上の整数演算・手作業特徴設計**という制約下で、CIFAR-10に対して70〜75%の精度を達成している。これは、SOTA（99%以上）との間に約25%の精度ギャップがあるが、この差は**設計思想の違い**を反映している。

#### CPU単体での限界

現在のアプローチは、以下の点でCPUの計算能力を十分に活用している：

1. **並列特徴抽出**: `ThreadPoolExecutor` による複数コア活用
2. **整数演算の最大化**: 浮動小数点演算を最小限に抑制
3. **メモリ効率**: memmapによるディスクキャッシュ、int16量子化

**結論**: 単純な計算速度向上の余地は限定的。**アーキテクチャ変更**が次の飛躍に必要。

---

### 発展の3つの方向性

本アプローチをさらに発展させるには、以下の3つの戦略的方向性が考えられる：

#### **方向性A: 設計思想を維持したまま深化する（推奨）**

**基本方針**: 説明可能性・CPU実装を維持し、**より洗練された構造表現**を追求

##### A1. 階層的マスク組み合わせ

現在のマスクは独立に扱われているが、マスク間の**論理演算・集合演算**により複合構造を表現：

```python
# 例: "高彩度かつエッジ" のようなAND/OR組み合わせ
composite_mask = (saturation_mask & edge_mask) | color_mask
```

- **利点**: 特徴の表現力向上、精度+5〜10%の見込み
- **実装コスト**: 低（既存コードベースに追加可能）
- **CPU負荷**: 軽微（ビット演算は高速）

##### A2. グラフ構造による空間関係の明示化

現在の特徴は「グリッド統計」だが、**マスクの空間的隣接関係**をグラフとして表現：

```python
# 連結成分をノード、隣接関係をエッジとするグラフ
G = build_spatial_graph(mask)
features = [degree_dist, clustering_coeff, diameter, ...]
```

- **理論的根拠**: グラフスペクトル理論、代数的トポロジー
- **利点**: トポロジカルな構造（穴、連結性）を捕捉
- **実装コスト**: 中（NetworkX等のライブラリ活用可能）
- **CPU負荷**: 中程度（小グラフなら実用的）

##### A3. 時間軸の拡張：動的システムとしてのマスク

セルオートマトンを1ステップではなく、**アトラクタ解析**として扱う：

```python
# リミットサイクル、固定点の検出
trajectory = run_ca_until_converge(mask, max_steps=20)
features = [cycle_length, attractor_type, Lyapunov_exponent, ...]
```

- **理論的根拠**: 力学系理論、カオス理論
- **利点**: マスクの「安定性」という新しい視点
- **実装コスト**: 中（カスタム実装が必要）

##### A4. 群論の深化：より大きな対称群

D4群の成功を踏まえ、**より豊かな対称性**を導入：

```python
# 例: スケール変換、アフィン変換のサブグループ
SE2_group = special_euclidean_2d()  # 回転+並進
features = extract_SE2_invariant(img)
```

- **理論的根拠**: Lie群、ゲージ理論
- **利点**: より高い汎化性能
- **実装コスト**: 高（数学的に複雑）
- **CPU負荷**: 中〜高

---

#### **方向性B: ハイブリッドアプローチ（中間戦略）**

**基本方針**: 設計思想の**コア**は維持しつつ、学習可能な要素を部分的に導入

##### B1. 学習可能な特徴選択

現在は全特徴を使用するが、**Lasso / Elastic Net**により重要特徴を自動選択：

```python
from sklearn.linear_model import LassoCV
selector = LassoCV(cv=5)
selected_features = selector.fit(X_train, y_train).support_
```

- **利点**: 高次元特徴の冗長性削減、精度向上
- **説明可能性**: 選択された特徴は依然として解釈可能
- **実装コスト**: 低（scikit-learn使用）

##### B2. カーネル法による非線形拡張

明示的に設計した特徴に対し、**カーネルトリック**で非線形変換：

```python
from sklearn.kernel_approximation import RBFSampler
kernel_transform = RBFSampler(gamma=0.1, n_components=1000)
X_nonlinear = kernel_transform.fit_transform(X_linear)
```

- **利点**: 線形分類器でも非線形境界を表現
- **説明可能性**: カーネルの解釈は可能（RBF = 距離ベース）
- **CPU負荷**: 中程度

##### B3. メタ学習による閾値最適化

マスク閾値をメタパラメータとして、**ベイズ最適化**で探索：

```python
from skopt import gp_minimize
def objective(thresholds):
    model = train_with_thresholds(thresholds)
    return -model.accuracy
best = gp_minimize(objective, search_space)
```

- **利点**: 手動調整を自動化、精度向上
- **説明可能性**: 特徴自体は手作業設計のまま
- **実装コスト**: 中（skopt等のライブラリ使用）

---

#### **方向性C: パラダイムシフト（設計思想の根本的変更）**

**基本方針**: 説明可能性を一部犠牲にし、**精度を最優先**

この方向性は、もはや「mymodel」の範疇を超え、以下のような選択肢となる：

##### C1. 軽量CNNへの移行

```python
# 例: MobileNetV3, EfficientNet-Lite
model = EfficientNetLite0(weights='imagenet')
model.fit(X_train, y_train)
```

- **精度**: 90%以上に到達可能
- **CPU実装**: TensorFlow Lite, ONNX Runtime で実用的
- **説明可能性**: **喪失**（ブラックボックス化）

##### C2. Vision Transformer（ViT）の採用

```python
from transformers import ViTForImageClassification
model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')
```

- **精度**: 95%以上に到達可能
- **計算量**: **GPU必須**（CPUでは非現実的）
- **設計思想**: **完全に放棄**

---

### 推奨戦略：方向性Aを主軸に、Bを補完的に導入

本プロジェクトの**アイデンティティ**を維持しつつ発展させるには：

#### フェーズ1（短期）: 方向性Aの実装

1. **階層的マスク組み合わせ（A1）**: 即座に実装可能、精度向上が期待できる
2. **学習可能な特徴選択（B1）**: Lassoによる次元削減

**期待効果**: 精度75% → 80%、計算時間±0%

#### フェーズ2（中期）: グラフ構造の導入

3. **空間グラフ特徴（A2）**: トポロジー情報の活用
4. **カーネル法（B2）**: 非線形性の獲得

**期待効果**: 精度80% → 85%、計算時間+20〜30%

#### フェーズ3（長期）: 理論的深化

5. **動的システム解析（A3）**: CAのアトラクタ解析
6. **より大きな対称群（A4）**: SE(2)群への拡張

**期待効果**: 精度85% → 90%、計算時間+50〜100%

---

### CPUの限界を超えるべきか？

#### 現状の評価

- **CPU性能**: 現代の多コアCPU（8〜16コア）は十分に活用されていない
- **並列化の余地**: より積極的なマルチプロセッシング（`multiprocessing`）で2〜4倍高速化可能
- **SIMD命令**: NumPyは自動でSIMD化されるが、カスタム実装でさらに最適化可能

#### GPU導入の是非

**GPU導入を避けるべき理由**:
1. **再現性の喪失**: CUDA版依存、環境差異の増大
2. **説明可能性の低下**: GPUに最適化されたアルゴリズムはブラックボックス化しやすい
3. **プロジェクトの独自性**: 「CPUでどこまでやれるか」が本質的価値

**GPU導入を検討すべきケース**:
- 精度90%以上が**必須要件**となった場合
- エッジデバイスではなく**サーバー環境**が主用途となった場合
- **ハイブリッド戦略**として、設計フェーズはCPU、推論フェーズはGPUという分離が可能な場合

---

### 設計思想の変更は必要か？

#### 現在の設計思想の強み

1. **説明可能性**: 全特徴の意味が明確
2. **再現性**: 誰でも同じ結果を得られる
3. **デバッグ容易性**: 各コンポーネントが独立してテスト可能
4. **教育的価値**: 画像認識の基本原理を学ぶ教材として優秀

#### 変更すべきでない理由

本プロジェクトは、**「深層学習とは異なる道」**の探究である。精度が目的ではなく、**理解可能な認識システムの構築**が目的である。この立場を堅持すべき。

#### 部分的変更が許容される範囲

- **自動パラメータ調整**: 閾値探索等は許容（特徴の解釈性は維持）
- **非線形変換**: カーネル法等は許容（明示的な特徴の上に構築）
- **アンサンブル**: 複数モデルの組み合わせは許容

#### 変更してはならない範囲

- **ブラックボックス化**: エンドツーエンド学習への完全移行
- **GPU依存**: CUDA必須のアルゴリズム採用
- **巨大モデル**: パラメータ数百万以上のモデル

---

### 結論：次の一手

**答え**: 設計思想の**本質**を変更する必要はない。むしろ、**洗練と深化**により、さらなる発展が可能である。

**具体的な次のステップ**:

1. **階層的マスク組み合わせ**を実装し、精度向上を確認（2週間）
2. **Lasso特徴選択**を導入し、冗長性を削減（1週間）
3. **グラフ構造特徴**の実験的実装（1ヶ月）
4. 結果を論文化し、「説明可能AI」「幾何学的深層学習」コミュニティに発表

**CPUの限界は超えていない**。現在の実装は、CPUの潜在能力の**50%程度**しか使っていない。並列化・SIMD最適化により、さらに2〜4倍の高速化が可能である。

**精度90%への道筋**は存在する。それは、GPU導入ではなく、**より賢い構造設計**によって達成されるべきである。

---

## 今後の展開 / Future Work

- **グラフ畳み込み**: マスク間の関係をグラフ構造として表現
- **Cayleyグラフ上の畳み込み**: D4群の構造を明示的に利用
- **動的マスク生成**: 強化学習によるマスク閾値の自動最適化
- **他データセットへの適用**: ImageNet-1k、STL-10等
- **組み込み実装**: マイコン・FPGA向けの整数専用版

---

## 謝辞 / Acknowledgments

本実装は、mymodel1の設計思想を継承しつつ、カラー画像認識への拡張を試みたものである。構造駆動型アプローチの可能性を信じ、実験的研究を続ける全ての研究者に敬意を表する。
